import matplotlib.pyplot as plt
import numpy as np
import pyaudio 
import struct
import sys 
import time 


#creacion del objeto principal para la captura de audio
class AudioStream(object):
    def __init__(self):
        
#constantes para capturar el audio 
        self.CHUNK = 1024 * 2
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 4800 #Fs
        self.pause = False

#creando el objeto que permite capturar el audio
        self.p = pyaudio.PyAudio()
        self.stream = self.p.open(
            format = self.FORMAT,
            channels = self.CHANNELS,
            rate = self.RATE,
            input = True,
            output = True,
            frames_per_buffer = self.CHUNK,
        )
        self.init_plots()
        self.start_plot()
        
#Creando los graficos
    def init_plots(self):
        
        #variables para gráficar x para tiempo Xs para frecuencia
        x = np.arange(0, 2*self.CHUNK, 2)
        xf = np.linspace(0, self.RATE, self.CHUNK)

        #creando la figura con las 2 gráficas dentro
        self.fig, (ax1, ax2) = plt.subplots(2, figsize = (15, 7))
        self.fig.canvas.mpl_connect('button_press_event', self.onClick)

        #graficando datos aleatorios en la gráfica de audio mientras no se reciba nada
        self.line, = ax1.plot(x, np.random.rand(self.CHUNK), '-', lw = 2)

        #graficando datos aleatorios en la gráfica de frecuencia mientras no se recibe nada 
        self.line_fft, = ax2.plot(xf, np.random.rand(self.CHUNK), '-', lw = 2)

        # definiendo los límites de la gráfica de audio en el dominio del tiempo
        ax1.set_title('señal de audio (dominio del tiempo)')
        ax1.set_ylabel('volumen')
        ax1.set_ylim(-10000, 10000)
        ax1.set_xlim(0, 2 * self.CHUNK)
        plt.setp(
            ax1, yticks = [0],
            xticks = [0, self.CHUNK, 2 * self.CHUNK],)
        
        # Definiendo los limites de la gráfica de audio en el dominio de la frecuencia
        ax2.set_title('señal de audio en el dominio de la frecuencia')
        ax2.set_xlabel('frecuencia')
        ax2.set_ylabel('amplitud')

        ax2.set_xlim(20, self.RATE / 12)
        plt.setp(
            ax2, yticks = [0, 5, 10, 15, 20],
                 xticks = [0, 100, 200, 300, 1000, 3000, 4000],)

        # mostrando ventana y definiendo sus dimensiones
        mngr = plt.get_current_fig_manager()
        mngr.window.setGeometry = (5, 120, 1910, 1070)
        plt.show(block=False)
        
        
        
#Actulizar las graficas en tiempo real
    def start_plot(self):
        
        print('stream started')
        frame_count = 0
        start_time = time.time()
        
        while not self.pause:
            #leyendo valores del microfono
            data = self.stream.read(self.CHUNK)

            #convirtiendo estos valores a enteros para poder usarlos
            data_int = np.frombuffer(data, dtype = 'h')
            
            #poniendo los valores enteros de dataint en un arreglo
            data_np = np.array(data_int, dtype = 'h')
            
            #agregando los valores a la grafica de audio en el dominio del tiempo (self.line)
            self.line.set_ydata(data_np)

            #calculo de la FFT
            yf = np.fft.fft(data_int)
            
            #agregar los valores de la FFT al gráfico (self.line_FTT)
            self.line_fft.set_ydata(
                np.abs(yf[0:self.CHUNK]) / (128 * self.CHUNK))
                        
            #Identificacion del pico de la frecuencia mas grande de todo el vector de la FFT
            f_vec1 = self.RATE * np.arange(self.CHUNK / 2) / self.CHUNK #Vector de frecuencia
            mic_low_freq1 = 40 #sensibilidad minima del microfono
            low_freq_loc1 = np.argmin(np.abs(f_vec1 - mic_low_freq1))
            fft_data1 = (np.abs(np.fft.fft(data_int))[0:int(np.floor(self.CHUNK / 2))])/self.CHUNK

            #Esta valiriable contiene el pico mas grande
            max_loc1 = np.argmax(fft_data1[low_freq_loc1:]) + low_freq_loc1

            print(f_vec1[max_loc1])

            #deteccion de la nota musical en un minimo de rango de frecuencia
            if 1640 <= f_vec1[max_loc1] <= 1660:
                print("2000hz: ", f_vec1[max_loc1])
            if 880 <= f_vec1[max_loc1] <= 900:
                print("600hz: ", f_vec1[max_loc1])
            if 750 <= f_vec1[max_loc1] <= 770:
                print("765hz: ", f_vec1[max_loc1])
            if 250 <= f_vec1[max_loc1] <= 280:
                print("269hz: ", f_vec1[max_loc1])

            self.fig.canvas.draw()
            self.fig.canvas.flush_events()
            frame_count += 1

        else:
            self.fr = frame_count / (time.time() - start_time) 
            print('average frame rate = {:.0f} FPS'.format(self.fr))
            self.exit_app()

    def exit_app(self):
        print('stream closed')
        self.p.close(self.stream)

#Si se hace click sobre la ventana, se termina el programa
    def onClick(self, event):
        self.pause = True
    
if __name__ == '__main__':
    AudioStream()
